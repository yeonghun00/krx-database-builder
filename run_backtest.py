#!/usr/bin/env python3
"""
V3 QEPM ë°±í…ŒìŠ¤íŠ¸ (Quantitative Equity Portfolio Management)

Usage:
    python3 run_backtest.py                         # ê¸°ë³¸ (quintile)
    python3 run_backtest.py --top 10                # ìƒìœ„ 10ê°œ ì¢…ëª©
    python3 run_backtest.py --qepm                  # ğŸ”¥ QEPM ëª¨ë“œ (ê¶Œì¥)
    python3 run_backtest.py --qepm --top 20         # QEPM + Top 20

QEPM ëª¨ë“œ:
    - 63ì¼(3ê°œì›”) í˜¸ë¼ì´ì¦Œ
    - Alpha íƒ€ê²Ÿ (ì‹œì¥ ëŒ€ë¹„ ì´ˆê³¼ìˆ˜ìµ)
    - ì„¹í„°ë‹¹ ìµœëŒ€ 3ì¢…ëª©
    - ë³€ë™ì„± ì—­ê°€ì¤‘ ë°°ë¶„
    - íšŒì „ìœ¨ ì œì–´ (20% ë²„í¼)
"""

import warnings
warnings.filterwarnings('ignore')

import logging
logging.basicConfig(level=logging.WARNING)

import pandas as pd
import numpy as np
import argparse
from scipy import stats
from datetime import datetime
import time
from ml.features import FeatureEngineer
from ml.model import MLRanker

parser = argparse.ArgumentParser()
parser.add_argument('--top', type=int, default=0, help='ìƒìœ„ Nê°œ ì¢…ëª©ë§Œ (0=quintile)')
parser.add_argument('--horizon', type=int, default=63, help='ë³´ìœ  ê¸°ê°„ (ì¼): 21, 63, 126')
parser.add_argument('--slippage', type=float, default=0.5, help='í¸ë„ ìŠ¬ë¦¬í”¼ì§€ %% (ê¸°ë³¸ 0.5%%)')
parser.add_argument('--qepm', action='store_true', help='ğŸ”¥ QEPM ëª¨ë“œ (63ì¼, Alpha, ì„¹í„°ì œí•œ, ë³€ë™ì„±ê°€ì¤‘)')
parser.add_argument('--max-sector', type=int, default=3, help='ì„¹í„°ë‹¹ ìµœëŒ€ ì¢…ëª© ìˆ˜ (QEPM)')
parser.add_argument('--turnover-buffer', type=float, default=0.2, help='íšŒì „ìœ¨ ë²„í¼ (ê¸°ì¡´ ì¢…ëª© êµì²´ ê¸°ì¤€)')
parser.add_argument('--v4', action='store_true', help='ğŸ”¥ V4 ëª¨ë“œ (ë§¤í¬ë¡œ Regime Detection í”¼ì²˜ ì¶”ê°€)')
parser.add_argument('--cash-timing', action='store_true', help='ğŸ›¡ï¸ í˜„ê¸ˆ ë¹„ì¤‘ ì¡°ì ˆ (ì‹œì¥ í•˜ë½ê¸° í˜„ê¸ˆ ë³´ìœ )')
parser.add_argument('--regime-threshold', type=float, default=-0.05, help='Regime ì„ê³„ê°’ (ê¸°ë³¸ -5%%: ì´í•˜ë©´ í˜„ê¸ˆ)')
parser.add_argument('--v42', action='store_true', help='ğŸ”¥ V4.2 Market Exit (Regime<0 â†’ 100%% í˜„ê¸ˆ, ì†ì ˆ, ì ìˆ˜í•„í„°)')
parser.add_argument('--stop-loss', type=float, default=0.07, help='V4.2 ì†ì ˆ ê¸°ì¤€ (ê¸°ë³¸ 7%%)')
parser.add_argument('--score-threshold', type=float, default=0.0, help='V4.2 ìµœì†Œ ML Score (ê¸°ë³¸ 0=ë¹„í™œì„±)')
parser.add_argument('--v43', action='store_true', help='ğŸ”¥ V4.3 Residual Alpha (Beta-neutral, Purged CV, ìœ ë™ì„±í•„í„°)')
parser.add_argument('--illiquidity-filter', type=float, default=0.9, help='V4.3 ìœ ë™ì„± í•„í„° (ìƒìœ„ N%% ì œì™¸, ê¸°ë³¸ 90%%=ìƒìœ„10%% ì œì™¸)')
parser.add_argument('--v5', action='store_true', help='ğŸ”¥ V5 Research-backed 10-Feature Mode (10ê°œ í•µì‹¬ í”¼ì²˜ë§Œ)')
args = parser.parse_args()

# QEPM ëª¨ë“œë©´ ì„¤ì • ì˜¤ë²„ë¼ì´ë“œ
if args.qepm:
    args.horizon = 63  # 3ê°œì›”
    if args.top == 0:
        args.top = 20  # ê¸°ë³¸ 20ì¢…ëª©

# V4.2 ëª¨ë“œ ì„¤ì • (ê³µê²©ì  Market Exit)
if args.v42:
    args.v4 = True  # V4 í”¼ì²˜ í¬í•¨
    args.cash_timing = True  # í˜„ê¸ˆ íƒ€ì´ë° í™œì„±í™”
    args.regime_threshold = 0.0  # Regime < 0ì´ë©´ í˜„ê¸ˆ (í•µì‹¬!)
    if args.top == 0:
        args.top = 20

# V4.3 ëª¨ë“œ ì„¤ì • (Residual Alpha + Purged CV)
if args.v43:
    args.v4 = True  # V4 í”¼ì²˜ í¬í•¨
    args.v42 = True  # V4.2 ê¸°ëŠ¥ í¬í•¨ (Market Exit)
    args.cash_timing = True
    args.regime_threshold = 0.0
    if args.top == 0:
        args.top = 20

# V5 ëª¨ë“œ ì„¤ì • (Research-backed 10-Feature Mode, cascades from v43)
if args.v5:
    args.v43 = True
    args.v42 = True
    args.v4 = True
    args.cash_timing = True
    args.regime_threshold = 0.0
    args.horizon = 63  # Forced to 63 days
    if args.top == 0:
        args.top = 20

print('=' * 70)
if args.v5:
    print('ğŸ”¥ V5 ë°±í…ŒìŠ¤íŠ¸ (Research-backed 10-Feature Mode)')
elif args.v43:
    print('ğŸ”¥ V4.3 ë°±í…ŒìŠ¤íŠ¸ (Residual Alpha + Beta Neutral)')
elif args.v42:
    print('ğŸ”¥ V4.2 ë°±í…ŒìŠ¤íŠ¸ (Market Exit Strategy)')
elif args.v4:
    print('ğŸ”¥ V4 ë°±í…ŒìŠ¤íŠ¸ (ë§¤í¬ë¡œ Regime Detection)')
elif args.qepm:
    print('ğŸ¦ V3 QEPM ë°±í…ŒìŠ¤íŠ¸ (ê¸°ê´€ê¸‰ í¬íŠ¸í´ë¦¬ì˜¤)')
else:
    print('ğŸš€ V3 ëª¨ë¸ ë°±í…ŒìŠ¤íŠ¸')
print(f'   {datetime.now().strftime("%Y-%m-%d %H:%M")}')
print('=' * 70)

# ============================================================================
# ì„¤ì •
# ============================================================================
HORIZON = args.horizon
TOP_N = args.top  # 0ì´ë©´ quintile ì‚¬ìš©
SLIPPAGE = args.slippage / 100  # í¸ë„ ìŠ¬ë¦¬í”¼ì§€ (0.5% -> 0.005)
ROUND_TRIP_COST = SLIPPAGE * 2  # ì™•ë³µ ë¹„ìš©
TRAIN_YEARS = 3
BUFFER_MONTHS = 2  # horizon ëŒ€ë¹„ ë²„í¼
QEPM_MODE = args.qepm
MAX_PER_SECTOR = args.max_sector
TURNOVER_BUFFER = args.turnover_buffer

print(f'\nì„¤ì •:')
print(f'  - ëª¨ë“œ: {"ğŸ¦ QEPM (ê¸°ê´€ê¸‰)" if QEPM_MODE else "ì¼ë°˜"}')
print(f'  - Target Horizon: {HORIZON}ì¼ ({HORIZON//21}ê°œì›”)')
print(f'  - í¬íŠ¸í´ë¦¬ì˜¤: {"ìƒìœ„ " + str(TOP_N) + "ê°œ" if TOP_N > 0 else "Quintile (ìƒìœ„ 20%)"}')
print(f'  - ìŠ¬ë¦¬í”¼ì§€: {args.slippage}% (ì™•ë³µ {args.slippage*2}%)')
if QEPM_MODE:
    print(f'  - ì„¹í„° ì œí•œ: ì„¹í„°ë‹¹ ìµœëŒ€ {MAX_PER_SECTOR}ì¢…ëª©')
    print(f'  - íšŒì „ìœ¨ ë²„í¼: {TURNOVER_BUFFER*100:.0f}% (êµì²´ ê¸°ì¤€)')
    print(f'  - íƒ€ê²Ÿ: Alpha (ì‹œì¥ ëŒ€ë¹„ ì´ˆê³¼ìˆ˜ìµ)')
    print(f'  - ê°€ì¤‘ì¹˜: ë³€ë™ì„± ì—­ê°€ì¤‘ (Risk Parity)')
print(f'  - í•™ìŠµ ê¸°ê°„: {TRAIN_YEARS}ë…„')
if args.v5:
    print(f'  - ğŸ”¥ V5 Research-backed 10-Feature Mode:')
    print(f'      â€¢ í”¼ì²˜: 10ê°œ í•µì‹¬ í”¼ì²˜ë§Œ ì‚¬ìš©')
    print(f'      â€¢ Horizon: 63ì¼ (forced)')
    print(f'      â€¢ Target: Residual Return (Beta-adjusted)')
    print(f'      â€¢ Purged CV + Market Exit + Macro ìƒì†')
elif args.v43:
    print(f'  - ğŸ”¥ V4.3 Residual Alpha:')
    print(f'      â€¢ Target: Residual Return (Beta-adjusted)')
    print(f'      â€¢ Purged CV: {HORIZON}ì¼ ê²¹ì¹¨ ì œê±°')
    print(f'      â€¢ ìœ ë™ì„± í•„í„°: Amihud ìƒìœ„ {(1-args.illiquidity_filter)*100:.0f}% ì œì™¸')
    print(f'      â€¢ Regime < {args.regime_threshold*100:.0f}% â†’ 100% í˜„ê¸ˆ')
elif args.v42:
    print(f'  - ğŸ”¥ V4.2 Market Exit:')
    print(f'      â€¢ Regime < {args.regime_threshold*100:.0f}% â†’ 100% í˜„ê¸ˆ')
    print(f'      â€¢ ì†ì ˆ ê¸°ì¤€: -{args.stop_loss*100:.0f}% (21ì¼ ë‚´)')
    if args.score_threshold > 0:
        print(f'      â€¢ ìµœì†Œ ML Score: {args.score_threshold}')
elif args.cash_timing:
    print(f'  - ğŸ›¡ï¸ í˜„ê¸ˆ íƒ€ì´ë°: ON (Regime < {args.regime_threshold*100:.0f}% â†’ í˜„ê¸ˆ)')

# ============================================================================
# ë°ì´í„° ë¡œë“œ
# ============================================================================
print('\n[1/3] ë°ì´í„° ë¡œë“œ ì¤‘...')
stage_t0 = time.time()

fe = FeatureEngineer('krx_stock_data.db')
df = fe.prepare_ml_data(
    start_date='20110101',  # ì „ì²´ ê¸°ê°„
    end_date='20260128',
    target_horizon=HORIZON,
    min_market_cap=500_000_000_000,
    include_fundamental=True,
    include_macro=args.v4  # V4: ë§¤í¬ë¡œ í”¼ì²˜ ì¶”ê°€
)
print(f'  â± [1/3] ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {time.time()-stage_t0:.1f}s')

# ============================================================================
# í˜„ê¸ˆ íƒ€ì´ë°ìš© ì‹œì¥ Regime ë°ì´í„° ë¡œë“œ (ìµœì í™”)
# ============================================================================
MARKET_REGIME = {}
if args.cash_timing:
    regime_t0 = time.time()
    import sqlite3
    conn = sqlite3.connect('krx_stock_data.db')
    # ë‹¨ìˆœ ì¿¼ë¦¬ë¡œ ë°ì´í„° ë¡œë“œ í›„ pandasì—ì„œ ê³„ì‚° (ë” ë¹ ë¦„)
    regime_query = '''
    SELECT date, closing_index
    FROM index_daily_prices
    WHERE index_code = 'KOSPI_ì½”ìŠ¤í”¼_200'
    ORDER BY date
    '''
    regime_df = pd.read_sql_query(regime_query, conn)
    conn.close()

    # Pandasì—ì„œ MA ê³„ì‚° (SQL windowë³´ë‹¤ ë¹ ë¦„)
    regime_df['ma_120'] = regime_df['closing_index'].rolling(120, min_periods=60).mean()
    regime_df['regime_score'] = (regime_df['closing_index'] / regime_df['ma_120']) - 1
    MARKET_REGIME = dict(zip(regime_df['date'], regime_df['regime_score']))

    # ì—°ë„ë³„ í‰ê·  regime í‘œì‹œ
    regime_df['year'] = regime_df['date'].str[:4]
    yearly_regime = regime_df.groupby('year')['regime_score'].mean()
    print(f'\n  [ì‹œì¥ Regime by Year]')
    for year, score in yearly_regime.items():
        if pd.notna(score):
            status = 'ğŸŸ¢' if score > 0 else 'ğŸ”´'
            print(f'    {year}: {score*100:+.1f}% {status}')
    print(f'  â± Market regime load: {time.time()-regime_t0:.1f}s')

def should_hold_cash(date, threshold):
    """í˜„ê¸ˆ ë³´ìœ  ì—¬ë¶€ ê²°ì •"""
    if not MARKET_REGIME:
        return False
    regime = MARKET_REGIME.get(date, 0)
    return regime < threshold

# í”¼ì²˜ ë¶„ë¥˜
momentum_features = [c for c in fe.MOMENTUM_FEATURES if c in df.columns]
volume_features = [c for c in fe.VOLUME_FEATURES if c in df.columns]
volatility_features = [c for c in fe.VOLATILITY_FEATURES if c in df.columns]
intuition_features = [c for c in fe.INTUITION_FEATURES if c in df.columns]
traditional_features = [c for c in fe.TRADITIONAL_FEATURES if c in df.columns]
fund_features = [c for c in fe.FUNDAMENTAL_FEATURES if c in df.columns]
macro_features = [c for c in fe.MACRO_FEATURES if c in df.columns] if args.v4 else []

all_features = (momentum_features + volume_features + volatility_features +
                intuition_features + traditional_features + fund_features + macro_features)

# V5: Override with 10 focused features
if args.v5:
    all_features = [c for c in fe.V5_FEATURES if c in df.columns]
    missing_v5 = [c for c in fe.V5_FEATURES if c not in df.columns]
    if missing_v5:
        print(f'  âš ï¸ Missing V5 features: {missing_v5}')

tech_count = len(momentum_features + volume_features + volatility_features +
                 intuition_features + traditional_features)

print(f'  ì´ ë°ì´í„°: {len(df):,} rows')
if args.v5:
    print(f'  í”¼ì²˜ êµ¬ì„±: V5 (10-Feature Mode)')
    for f_name in all_features:
        print(f'    - {f_name}')
    print(f'  ì´ í”¼ì²˜: {len(all_features)}ê°œ')
else:
    print(f'  í”¼ì²˜ êµ¬ì„±:')
    print(f'    - ëª¨ë©˜í…€: {len(momentum_features)}ê°œ')
    print(f'    - ìˆ˜ê¸‰: {len(volume_features)}ê°œ')
    print(f'    - ë³€ë™ì„±: {len(volatility_features)}ê°œ')
    print(f'    - ë³¸ëŠ¥ì „ëµ: {len(intuition_features)}ê°œ')
    print(f'    - ì „í†µì§€í‘œ: {len(traditional_features)}ê°œ')
    print(f'    - ì¬ë¬´: {len(fund_features)}ê°œ')
    if args.v4:
        print(f'    - ğŸ”¥ ë§¤í¬ë¡œ: {len(macro_features)}ê°œ')
    print(f'  ì¬ë¬´ ë¹„ì¤‘: {len(fund_features)/len(all_features)*100:.1f}%')

# Forward return ì¶”ê°€
df = df.sort_values(['stock_code', 'date'])
df['year'] = df['date'].str[:4].astype(int)
years = sorted(df['year'].unique())

# ============================================================================
# Walk-Forward ë°±í…ŒìŠ¤íŠ¸
# ============================================================================
stage_t0 = time.time()
print('\n[2/3] Walk-Forward ë°±í…ŒìŠ¤íŠ¸...')
print('-' * 70)

# íƒ€ê²Ÿ ì„¤ì •: V4.3 > QEPM > ì¼ë°˜
if args.v43:
    # ğŸ”¥ V4.3: Residual Return (Beta-adjusted) íƒ€ê²Ÿ
    target_col = f'target_residual_rank_{HORIZON}d'
    return_col = f'forward_return_{HORIZON}d'  # ì‹¤ì œ ìˆ˜ìµì€ raw return
    if target_col not in df.columns:
        print(f'  âš ï¸ Residual target ì—†ìŒ, Alphaë¡œ fallback')
        target_col = f'target_alpha_rank_{HORIZON}d'
elif QEPM_MODE:
    target_col = f'target_alpha_rank_{HORIZON}d'  # Alpha ìˆœìœ„
    return_col = f'forward_alpha_{HORIZON}d'      # Alpha ìˆ˜ìµë¥ 
    if target_col not in df.columns:
        target_col = f'target_rank_{HORIZON}d'    # fallback
        return_col = f'forward_return_{HORIZON}d'
else:
    target_col = f'target_rank_{HORIZON}d'
    return_col = f'forward_return_{HORIZON}d'

# V4.3: ìœ ë™ì„± í•„í„° ì ìš©
if args.v43 and 'amihud_rank' in df.columns:
    original_len = len(df)
    df = df[df['amihud_rank'] <= args.illiquidity_filter]
    filtered = original_len - len(df)
    print(f'  ìœ ë™ì„± í•„í„°: {filtered:,}ê°œ ì œì™¸ (Amihud ìƒìœ„ {(1-args.illiquidity_filter)*100:.0f}%)')

all_results = []

# ============================================================================
# QEPM í—¬í¼ í•¨ìˆ˜ë“¤
# ============================================================================

def load_all_benchmark_returns(horizon=63):
    """
    ëª¨ë“  ì—°ë„ì˜ ë²¤ì¹˜ë§ˆí¬ ìˆ˜ìµë¥ ì„ í•œ ë²ˆì— ë¡œë“œ (ìºì‹œìš©)
    """
    import sqlite3

    try:
        conn = sqlite3.connect('krx_stock_data.db')
        query = f"""
        SELECT
            SUBSTR(date, 1, 4) as year,
            AVG(return_{horizon}d) * 100 as avg_return
        FROM benchmark_kospi200
        WHERE return_{horizon}d IS NOT NULL
        GROUP BY SUBSTR(date, 1, 4)
        """
        result = pd.read_sql_query(query, conn)
        conn.close()

        return dict(zip(result['year'].astype(int), result['avg_return']))
    except Exception as e:
        print(f'    âš ï¸ ë²¤ì¹˜ë§ˆí¬ ë¡œë“œ ì‹¤íŒ¨: {e}')
        return {}

# ë²¤ì¹˜ë§ˆí¬ ë°ì´í„° ë¯¸ë¦¬ ë¡œë“œ (í•œ ë²ˆë§Œ)
_BENCHMARK_CACHE = None

def get_benchmark_return(year, horizon=63):
    """ìºì‹œëœ ë²¤ì¹˜ë§ˆí¬ ìˆ˜ìµë¥  ë°˜í™˜"""
    global _BENCHMARK_CACHE
    if _BENCHMARK_CACHE is None:
        _BENCHMARK_CACHE = load_all_benchmark_returns(horizon)
    return _BENCHMARK_CACHE.get(year, 0)

def select_with_sector_constraint(df, top_n, max_per_sector):
    """ì„¹í„° ì œì•½ ì ìš©í•œ ì¢…ëª© ì„ ì • (ë²¡í„°í™” ë²„ì „)"""
    if len(df) == 0:
        return df

    df = df.sort_values('pred_rank').copy()
    df['sector'] = df['sector'].fillna('Unknown')

    # ì„¹í„°ë³„ ëˆ„ì  ì¹´ìš´íŠ¸ ê³„ì‚° (ë²¡í„°í™”)
    df['_sector_cumcount'] = df.groupby('sector').cumcount() + 1

    # ì„¹í„°ë‹¹ max_per_sector ì´í•˜ì¸ í–‰ë§Œ ì„ íƒ
    eligible = df[df['_sector_cumcount'] <= max_per_sector]

    # ìƒìœ„ top_nê°œ ì„ íƒ
    result = eligible.head(top_n).drop(columns=['_sector_cumcount'])
    return result

def apply_inverse_volatility_weight(df, return_col):
    """ë³€ë™ì„± ì—­ê°€ì¤‘ ì ìš©í•œ ìˆ˜ìµë¥  ê³„ì‚°"""
    if 'volatility_20d' not in df.columns or len(df) == 0:
        return df[return_col].mean()

    vol = df['volatility_20d'].fillna(df['volatility_20d'].median())
    vol = vol.clip(lower=0.1)  # ìµœì†Œ ë³€ë™ì„±
    inv_vol = 1 / vol
    weights = inv_vol / inv_vol.sum()

    return (df[return_col] * weights).sum()

for test_year in years:
    train_start = test_year - TRAIN_YEARS
    train_end = test_year - 1

    # Buffer ì ìš© (horizon ê±°ë˜ì¼ ì „ì— í•™ìŠµ ì¢…ë£Œ)
    buffer_month = 12 - (HORIZON // 21 + BUFFER_MONTHS)
    buffer_month = max(1, min(buffer_month, 10))
    train_cutoff = f'{train_end}{buffer_month:02d}01'

    train_df = df[(df['year'] >= train_start) &
                  (df['year'] <= train_end) &
                  (df['date'] <= train_cutoff)].copy()
    test_df = df[df['year'] == test_year].copy()

    if len(train_df) < 1000 or len(test_df) < 100:
        continue

    # ================================================================
    # V4.3: Purged Cross-Validation (De Prado, 2018)
    # Forward returnì´ ê²¹ì¹˜ëŠ” ë°ì´í„° ì œê±° â†’ Data leakage ë°©ì§€
    # ================================================================
    if args.v43:
        # í…ŒìŠ¤íŠ¸ ì‹œì‘ì¼ ê¸°ì¤€ìœ¼ë¡œ HORIZONì¼ ì´ì „ê¹Œì§€ë§Œ í•™ìŠµ
        test_start_date = test_df['date'].min()
        # Purge: í…ŒìŠ¤íŠ¸ ì‹œì‘ - horizonì¼ ì „ê¹Œì§€ë§Œ í•™ìŠµ ë°ì´í„° ì‚¬ìš©
        # (forward return ê³„ì‚° ì‹œ ê²¹ì¹˜ëŠ” ë¶€ë¶„ ì œê±°)
        purge_cutoff = pd.to_datetime(test_start_date, format='%Y%m%d') - pd.Timedelta(days=HORIZON * 1.5)
        purge_cutoff_str = purge_cutoff.strftime('%Y%m%d')

        original_train_len = len(train_df)
        train_df = train_df[train_df['date'] <= purge_cutoff_str]
        purged = original_train_len - len(train_df)

        # Embargo: ë² ì–´ë§ˆì¼“ ë°ì´í„°ì— ê°€ì¤‘ì¹˜ ë¶€ì—¬ (2022-2023)
        if 'macro_risk_score' in train_df.columns:
            # ê³ ìœ„í—˜ ê¸°ê°„ì— 2x ê°€ì¤‘ì¹˜
            train_df['sample_weight'] = 1.0
            high_risk_mask = train_df['macro_risk_score'] > 0.6
            train_df.loc[high_risk_mask, 'sample_weight'] = 2.0
        else:
            train_df['sample_weight'] = 1.0

    # ëª¨ë¸ í•™ìŠµ
    model = MLRanker(
        feature_cols=all_features,
        target_col=target_col,
        model_type='regressor',
        time_decay=0.5 if QEPM_MODE else 0.7
    )

    # V4.3: Sample weight ì ìš©
    if args.v43 and 'sample_weight' in train_df.columns:
        model.train(train_df, sample_weight=train_df['sample_weight'].values)
    else:
        model.train(train_df)

    # ì˜ˆì¸¡
    test_df['pred_score'] = model.predict(test_df)
    test_df['pred_rank'] = test_df.groupby('date')['pred_score'].rank(ascending=False)

    # ğŸ”¥ V4.2: ML Score ì •ê·œí™” (0~1 ë²”ìœ„ë¡œ) ë° ì„ê³„ê°’ í•„í„°
    score_filtered = False
    if args.v42 and args.score_threshold > 0:
        # ë‚ ì§œë³„ ì ìˆ˜ ì •ê·œí™” (percentile)
        test_df['pred_score_pct'] = test_df.groupby('date')['pred_score'].rank(pct=True)
        # ì„ê³„ê°’ ë¯¸ë‹¬ ì¢…ëª© í•„í„° (pred_rankì„ ë†’ì—¬ì„œ ì„ íƒ ì•ˆë˜ê²Œ)
        low_score_mask = test_df['pred_score_pct'] < args.score_threshold
        if low_score_mask.any():
            score_filtered = True

    if TOP_N > 0:
        if QEPM_MODE:
            # QEPM: ì„¹í„° ì œì•½ + ë³€ë™ì„± ê°€ì¤‘ (ì™„ì „ ë²¡í„°í™”)
            test_df = test_df.sort_values(['date', 'pred_rank']).copy()
            test_df['sector'] = test_df['sector'].fillna('Unknown')

            # ì„¹í„°ë³„ ëˆ„ì  ì¹´ìš´íŠ¸ (ë‚ ì§œ+ì„¹í„° ê·¸ë£¹ë³„)
            test_df['_sector_cumcount'] = test_df.groupby(['date', 'sector']).cumcount() + 1
            test_df['_date_cumcount'] = test_df.groupby('date').cumcount() + 1

            # ì„¹í„° ì œì•½ + Top N í•„í„° (ì™„ì „ ë²¡í„°í™”)
            top_df = test_df[
                (test_df['_sector_cumcount'] <= MAX_PER_SECTOR) &
                (test_df['_date_cumcount'] <= TOP_N * 2)  # ì—¬ìœ ìˆê²Œ í•„í„°
            ].copy()

            # ë‚ ì§œë³„ë¡œ ë‹¤ì‹œ Top N ì„ íƒ
            top_df['_final_rank'] = top_df.groupby('date').cumcount() + 1
            top_df = top_df[top_df['_final_rank'] <= TOP_N]

            # ë³€ë™ì„± ì—­ê°€ì¤‘ ìˆ˜ìµë¥  (ë²¡í„°í™”)
            if 'volatility_20d' in top_df.columns:
                vol = top_df['volatility_20d'].fillna(top_df['volatility_20d'].median()).clip(lower=0.1)
                top_df['_inv_vol'] = 1 / vol
                top_df['_weight'] = top_df.groupby('date')['_inv_vol'].transform(lambda x: x / x.sum())
                q5_raw = (top_df[return_col] * top_df['_weight']).groupby(top_df['date']).sum().mean() * 100
            else:
                q5_raw = top_df[return_col].mean() * 100
        else:
            # ì¼ë°˜: ë‹¨ìˆœ Top N
            top_df = test_df[test_df['pred_rank'] <= TOP_N]
            q5_raw = top_df[return_col].mean() * 100

        # Bottom N (ë²¡í„°í™”)
        max_rank = test_df.groupby('date')['pred_rank'].transform('max')
        bottom_df = test_df[test_df['pred_rank'] > max_rank - TOP_N]
        q1_raw = bottom_df[return_col].mean() * 100

        # QEPMì€ íšŒì „ìœ¨ ê°ì†Œë¡œ ìŠ¬ë¦¬í”¼ì§€ 1/3
        effective_slippage = ROUND_TRIP_COST / 3 if QEPM_MODE else ROUND_TRIP_COST
        q5 = q5_raw - effective_slippage * 100
        q1 = q1_raw - effective_slippage * 100
        spread = q5 - q1 if not (np.isnan(q5) or np.isnan(q1)) else np.nan
    else:
        # Quintile ìˆ˜ìµë¥ 
        test_df['quintile'] = pd.qcut(
            test_df['pred_rank'], 5,
            labels=[5,4,3,2,1], duplicates='drop'  # 1=top, 5=bottom
        )
        quintile_ret = test_df.groupby('quintile')[return_col].mean() * 100
        q1_raw = quintile_ret.get(1, np.nan)  # Bottom 20%
        q5_raw = quintile_ret.get(5, np.nan)  # Top 20%
        # ìŠ¬ë¦¬í”¼ì§€ ì ìš© (ì™•ë³µ ë¹„ìš© ì°¨ê°)
        q5 = q5_raw - ROUND_TRIP_COST * 100 if not np.isnan(q5_raw) else np.nan
        q1 = q1_raw - ROUND_TRIP_COST * 100 if not np.isnan(q1_raw) else np.nan
        spread = q5 - q1 if not (np.isnan(q5) or np.isnan(q1)) else np.nan

    # IC ê³„ì‚°
    ic, _ = stats.spearmanr(
        test_df['pred_score'].fillna(0),
        test_df[return_col].fillna(0)
    )

    # QEPM: ì‹œì¥(KOSPI200) ìˆ˜ìµë¥  - DBì—ì„œ ê°€ì ¸ì˜¤ê¸°
    if QEPM_MODE:
        market_ret = get_benchmark_return(test_year, HORIZON)
        abs_top = q5 + market_ret  # ì ˆëŒ€ ìˆ˜ìµë¥  = Alpha + ì‹œì¥
        abs_bot = q1 + market_ret
    else:
        market_ret = 0
        abs_top = q5
        abs_bot = q1

    # ì‹¤ì œ í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥  ê³„ì‚° (Alpha ì•„ë‹Œ ì ˆëŒ€ ìˆ˜ìµë¥ !)
    abs_return_col = f'forward_return_{HORIZON}d'
    if TOP_N > 0 and abs_return_col in test_df.columns:
        if QEPM_MODE:
            # QEPM: top_df ì¬ì‚¬ìš© (ì´ë¯¸ ì„¹í„° ì œì•½ ì ìš©ë¨)
            portfolio_return = top_df[abs_return_col].mean() * 100 - ROUND_TRIP_COST * 100
        else:
            # ì¼ë°˜: Top N í‰ê· 
            portfolio_return = top_df[abs_return_col].mean() * 100 - ROUND_TRIP_COST * 100
    else:
        portfolio_return = q5  # fallback

    # ğŸ›¡ï¸ í˜„ê¸ˆ íƒ€ì´ë°: ì‹œì¥ Regimeì´ ë‚˜ì˜ë©´ í˜„ê¸ˆ ë³´ìœ  (0% ìˆ˜ìµ)
    held_cash = False
    cash_ratio = 0.0
    stop_loss_impact = 0.0

    if args.cash_timing and MARKET_REGIME:
        year_dates = [d for d in MARKET_REGIME.keys() if d.startswith(str(test_year))]
        if year_dates:
            regimes = [MARKET_REGIME[d] for d in year_dates if pd.notna(MARKET_REGIME[d])]
            if regimes:
                avg_regime = np.mean(regimes)

                if args.v42:
                    # ğŸ”¥ V4.2: ê³µê²©ì  Market Exit
                    # Regime < 0 (MA ì´í•˜)ì´ë©´ í•´ë‹¹ ê¸°ê°„ 100% í˜„ê¸ˆ
                    bad_days = sum(1 for r in regimes if r < args.regime_threshold)
                    cash_ratio = bad_days / len(regimes)

                    if cash_ratio > 0:
                        held_cash = True
                        # í˜„ê¸ˆ ë³´ìœ  ê¸°ê°„ì˜ ìˆ˜ìµ = 0 (ì†ì‹¤ íšŒí”¼)
                        # íˆ¬ì ê¸°ê°„ì˜ ìˆ˜ìµë§Œ ë°˜ì˜
                        portfolio_return = portfolio_return * (1 - cash_ratio)

                    # ğŸ”¥ V4.2: ì†ì ˆ ì‹œë®¬ë ˆì´ì…˜ (21ì¼ ë‚´ -7% í•˜ë½ ì‹œ)
                    # ì†ì ˆëœ ì¢…ëª©ì€ ìˆ˜ìµ ê¸°ì—¬ë„ê°€ ë‚®ì•„ì§
                    if abs_return_col in top_df.columns and 'drawdown_from_high' in top_df.columns:
                        # í° ë‚™í­ ì¢…ëª© ë¹„ìœ¨ ê³„ì‚° (ì†ì ˆ ì‹œë®¬ë ˆì´ì…˜)
                        severe_drawdown = top_df['drawdown_from_high'] < -args.stop_loss
                        stop_loss_ratio = severe_drawdown.mean() if len(top_df) > 0 else 0

                        # ì†ì ˆ ì¢…ëª©ì˜ ì†ì‹¤ ì œí•œ (-7%ì—ì„œ ì†ì ˆ)
                        if stop_loss_ratio > 0:
                            avg_loss_avoided = (top_df.loc[severe_drawdown, abs_return_col].mean() + args.stop_loss)
                            if pd.notna(avg_loss_avoided) and avg_loss_avoided < 0:
                                stop_loss_impact = -avg_loss_avoided * stop_loss_ratio * 100
                                portfolio_return += stop_loss_impact
                else:
                    # ê¸°ì¡´ ë°©ì‹: ë¶€ë¶„ í˜„ê¸ˆ ë¹„ì¤‘ ì¡°ì ˆ
                    bad_days = sum(1 for r in regimes if r < args.regime_threshold or r > 0.15)
                    cash_ratio = bad_days / len(regimes)

                    if cash_ratio > 0.2:
                        held_cash = True
                        portfolio_return = portfolio_return * (1 - min(cash_ratio, 0.8))

    # ì—°ê°„ ì‹¤ì œ ìˆ˜ìµë¥  = ë¶„ê¸° ìˆ˜ìµë¥  ë³µë¦¬ (4íšŒ ë¦¬ë°¸ëŸ°ì‹± ê°€ì •)
    annual_portfolio = ((1 + portfolio_return/100) ** (252/HORIZON) - 1) * 100

    all_results.append({
        'year': test_year,
        'Q1': q1,
        'Q5': q5,
        'spread': spread,
        'IC': ic,
        'market_ret': market_ret,
        'abs_top': abs_top,
        'portfolio_return': portfolio_return,  # ì‹¤ì œ ë¶„ê¸° ìˆ˜ìµë¥ 
        'annual_return': annual_portfolio,     # ì‹¤ì œ ì—°í™˜ì‚° ìˆ˜ìµë¥ 
        'train_samples': len(train_df),
        'test_samples': len(test_df),
        'held_cash': held_cash,
        'cash_ratio': cash_ratio,              # V4.2: í˜„ê¸ˆ ë³´ìœ  ë¹„ìœ¨
        'stop_loss_impact': stop_loss_impact   # V4.2: ì†ì ˆ íš¨ê³¼
    })

    if not np.isnan(spread):
        bar = 'â–ˆ' * int(max(0, min(annual_portfolio, 50)))
        ic_status = 'âœ…' if ic > 0 else 'âŒ'
        if args.v42 and held_cash:
            cash_status = f'ğŸ’µ{cash_ratio*100:.0f}%'
        elif held_cash:
            cash_status = 'ğŸ’µ'
        else:
            cash_status = ''
        # ëª¨ë“  ëª¨ë“œì—ì„œ ì‹¤ì œ ì—°ìˆ˜ìµë¥  í‘œì‹œ
        print(f'  {test_year}: ë¶„ê¸°={portfolio_return:+5.1f}% | ì—°í™˜ì‚°={annual_portfolio:+5.1f}% | IC={ic:+.3f} {ic_status} {cash_status} {bar}')

print(f'  â± [2/3] Walk-Forward ë°±í…ŒìŠ¤íŠ¸: {time.time()-stage_t0:.1f}s')

# ============================================================================
# ê²°ê³¼ ë¶„ì„
# ============================================================================
stage_t0 = time.time()
print('\n[3/3] ê²°ê³¼ ë¶„ì„')
print('=' * 70)

results_df = pd.DataFrame(all_results)

# ìµœê·¼ 5ë…„ vs ì „ì²´
recent_5y = results_df[results_df['year'] >= 2021]
all_years = results_df

print('\n[ì„±ê³¼ ìš”ì•½]')
print('-' * 50)
print(f'{"ê¸°ê°„":<15} {"í‰ê·  Spread":>12} {"í‰ê·  IC":>10} {"IC ì–‘ìˆ˜ìœ¨":>10}')
print('-' * 50)

for name, data in [('ì „ì²´', all_years), ('ìµœê·¼ 5ë…„', recent_5y)]:
    avg_spread = data['spread'].mean()
    avg_ic = data['IC'].mean()
    ic_positive = (data['IC'] > 0).sum() / len(data) * 100
    print(f'{name:<15} {avg_spread:>+11.1f}% {avg_ic:>+9.3f} {ic_positive:>9.0f}%')

print('-' * 50)

# IC ë¶„ì„
print('\n[ì—°ë„ë³„ IC]')
print('-' * 50)
for _, row in results_df.iterrows():
    ic = row['IC']
    bar = 'â–ˆ' * int(max(0, (ic + 0.1) * 100)) if ic > -0.1 else 'â–‘' * int(min(10, abs(ic) * 100))
    status = 'âœ…' if ic > 0.02 else 'âš ï¸' if ic > 0 else 'âŒ'
    print(f"  {int(row['year'])}: IC = {ic:+.3f} {status} {bar}")

# V1 vs V2 ë¹„êµ (ì˜ˆìƒ)
print('\n[V1 vs V2 ë¹„êµ]')
print('-' * 50)
print('  V1 (ì¬ë¬´ 84%): IC â‰ˆ 0, Q5 < Q1')
print(f'  V2 (ëª¨ë©˜í…€ ì¤‘ì‹¬): IC = {results_df["IC"].mean():+.3f}, Spread = {results_df["spread"].mean():+.1f}%')

# í”¼ì²˜ ì¤‘ìš”ë„
print('\n[V2 í”¼ì²˜ ì¤‘ìš”ë„ Top 15]')
print('-' * 50)

# ë§ˆì§€ë§‰ ëª¨ë¸ì˜ í”¼ì²˜ ì¤‘ìš”ë„
importance = model.feature_importance()

for i, row in importance.head(15).iterrows():
    feature = row['feature']
    imp = row['importance']

    # ê·¸ë£¹ ë¶„ë¥˜
    if args.v5:
        group = 'V5'
    elif feature in momentum_features:
        group = 'ëª¨ë©˜í…€'
    elif feature in volume_features:
        group = 'ìˆ˜ê¸‰'
    elif feature in volatility_features:
        group = 'ë³€ë™ì„±'
    elif feature in intuition_features:
        group = 'ë³¸ëŠ¥'
    elif feature in traditional_features:
        group = 'ì „í†µ'
    elif args.v4 and feature in macro_features:
        group = 'ë§¤í¬ë¡œ'
    else:
        group = 'ì¬ë¬´'

    bar = 'â–ˆ' * int(imp / importance['importance'].max() * 20)
    print(f'  {feature:<25} [{group:<4}] {bar}')

# ê·¸ë£¹ë³„ ì¤‘ìš”ë„
print('\n[ê·¸ë£¹ë³„ í”¼ì²˜ ì¤‘ìš”ë„]')
print('-' * 50)

if args.v5:
    groups = {'V5': all_features}
else:
    groups = {
        'ëª¨ë©˜í…€': momentum_features,
        'ìˆ˜ê¸‰': volume_features,
        'ë³€ë™ì„±': volatility_features,
        'ë³¸ëŠ¥ì „ëµ': intuition_features,
        'ì „í†µì§€í‘œ': traditional_features,
        'ì¬ë¬´': fund_features,
    }
    if args.v4:
        groups['ë§¤í¬ë¡œ'] = macro_features

total_imp = importance['importance'].sum()
for group_name, group_features in groups.items():
    group_imp = importance[importance['feature'].isin(group_features)]['importance'].sum()
    pct = group_imp / total_imp * 100
    bar = 'â–ˆ' * int(pct / 5)
    print(f'  {group_name:<10} {pct:>5.1f}% {bar}')

# ìµœì¢… íŒì •
print('\n' + '=' * 70)
print('ğŸ’° ì‹¤ì œ í¬íŠ¸í´ë¦¬ì˜¤ ì—°ê°„ ìˆ˜ìµë¥ ')
print('=' * 70)

avg_ic = results_df['IC'].mean()
avg_spread = results_df['spread'].mean()
ic_positive_rate = (results_df['IC'] > 0).sum() / len(results_df) * 100

# ============================================================================
# í•µì‹¬: ì‹¤ì œ ì—°ê°„ ìˆ˜ìµë¥  (ì„ íƒëœ ì¢…ëª© ê¸°ë°˜)
# ============================================================================
print(f'\n  [ì—°ë„ë³„ ì‹¤ì œ ìˆ˜ìµë¥ ] (Top {TOP_N}ê°œ ì¢…ëª©, ìŠ¬ë¦¬í”¼ì§€ {args.slippage}% ë°˜ì˜)')
print('  ' + '-' * 55)
print(f'  {"ì—°ë„":<6} {"ë¶„ê¸°ìˆ˜ìµë¥ ":>12} {"ì—°í™˜ì‚°":>12} {"IC":>8}  ìƒíƒœ')
print('  ' + '-' * 55)

annual_returns = []
for _, row in results_df.iterrows():
    year = int(row['year'])
    qtr_ret = row['portfolio_return']
    ann_ret = row['annual_return']
    ic = row['IC']

    # NaN ì²´í¬ (ë¯¸ë˜ ë°ì´í„° ì—†ëŠ” ì—°ë„ ìŠ¤í‚µ)
    if pd.isna(ann_ret) or pd.isna(qtr_ret):
        continue

    annual_returns.append(ann_ret)

    # ìƒíƒœ ë°”
    if ann_ret > 20:
        bar = 'ğŸ”¥' + 'â–ˆ' * min(10, int(ann_ret / 5))
    elif ann_ret > 0:
        bar = 'âœ…' + 'â–“' * min(10, int(ann_ret / 3))
    else:
        bar = 'âŒ' + 'â–‘' * min(10, int(abs(ann_ret) / 3))

    print(f'  {year:<6} {qtr_ret:>+11.1f}% {ann_ret:>+11.1f}% {ic:>+7.3f}  {bar}')

print('  ' + '-' * 55)

# ìš”ì•½ í†µê³„
avg_annual = np.mean(annual_returns)
median_annual = np.median(annual_returns)
std_annual = np.std(annual_returns)
min_annual = np.min(annual_returns)
max_annual = np.max(annual_returns)
positive_years = sum(1 for r in annual_returns if r > 0)
total_years = len(annual_returns)

print(f'\n  ğŸ“Š ìš”ì•½ í†µê³„')
print('  ' + '-' * 55)
print(f'    í‰ê·  ì—°ìˆ˜ìµë¥ :    {avg_annual:>+8.1f}%')
print(f'    ì¤‘ì•™ê°’ ì—°ìˆ˜ìµë¥ :  {median_annual:>+8.1f}%')
print(f'    í‘œì¤€í¸ì°¨:         {std_annual:>8.1f}%')
print(f'    ìµœê³  ì—°ë„:        {max_annual:>+8.1f}%')
print(f'    ìµœì•… ì—°ë„:        {min_annual:>+8.1f}%')
print(f'    ìˆ˜ìµ ì—°ë„:        {positive_years}/{total_years}ë…„ ({positive_years/total_years*100:.0f}%)')

# í•µì‹¬ ê²°ë¡ 
print('\n  ' + '=' * 55)
if avg_annual > 15:
    emoji = 'ğŸ”¥'
elif avg_annual > 5:
    emoji = 'âœ…'
elif avg_annual > 0:
    emoji = 'âš ï¸'
else:
    emoji = 'âŒ'
print(f'  {emoji} í‰ê·  ì—°ìˆ˜ìµë¥ : {avg_annual:+.1f}% (ì¤‘ì•™ê°’: {median_annual:+.1f}%)')
print('  ' + '=' * 55)

# ëª¨ë¸ í’ˆì§ˆ ìš”ì•½
print(f'\n  [ëª¨ë¸ í’ˆì§ˆ]')
print(f'    í‰ê·  IC: {avg_ic:+.3f}')
print(f'    IC ì–‘ìˆ˜ìœ¨: {ic_positive_rate:.0f}%')

# V4.2 ì „ìš© ìš”ì•½
if args.v42:
    print(f'\n  [V4.2 Market Exit íš¨ê³¼]')
    print('  ' + '-' * 55)
    avg_cash_ratio = results_df['cash_ratio'].mean() * 100
    total_stop_loss = results_df['stop_loss_impact'].sum()
    cash_years = (results_df['held_cash']).sum()
    print(f'    í‰ê·  í˜„ê¸ˆ ë³´ìœ  ë¹„ìœ¨: {avg_cash_ratio:.1f}%')
    print(f'    í˜„ê¸ˆ ë³´ìœ  ì—°ë„: {cash_years}/{len(results_df)}ë…„')
    print(f'    ì†ì ˆë¡œ íšŒí”¼í•œ ì†ì‹¤: {total_stop_loss:+.1f}%')

# ============================================================================
# ì•ˆì „ì„± ì²´í¬ (Safety Check)
# ============================================================================
print('\n' + '=' * 70)
print('ğŸ›¡ï¸  ì•ˆì „ì„± ì²´í¬')
print('=' * 70)

safety_checks = {}

# 1. IC ì•ˆì •ì„±
ic_stable = avg_ic >= 0.02 and ic_positive_rate >= 50
safety_checks['IC ì•ˆì •ì„± (ICâ‰¥0.02, ì–‘ìˆ˜ìœ¨â‰¥50%)'] = ic_stable

# 2. ìˆ˜ìµë¥  ì•ˆì •ì„± (ì—°í™˜ì‚° ìˆ˜ìµë¥  ë³€ë™)
ret_stable = std_annual < 25.0  # ì—°í™˜ì‚°ì´ë¼ ê¸°ì¤€ ì™„í™”
safety_checks[f'ìˆ˜ìµë¥  ì•ˆì •ì„± (Ïƒ={std_annual:.1f}% < 25%)'] = ret_stable

# 3. ì†ì‹¤ ì—°ë„ ì²´í¬
loss_years = total_years - positive_years
loss_check = loss_years <= total_years * 0.4  # 40% ì´í•˜ ì†ì‹¤ì—°ë„
safety_checks[f'ì†ì‹¤ì—°ë„ ({loss_years}/{total_years} â‰¤ 40%)'] = loss_check

# 4. ìµœì•…ì˜ í•´ ì²´í¬
worst_check = min_annual > -20.0  # ì—°í™˜ì‚° ê¸°ì¤€ -20% ì´ìƒ
safety_checks[f'ìµœì•…ì˜ í•´ ({min_annual:+.1f}% > -20%)'] = worst_check

# 5. ì—°í™˜ì‚° ìˆ˜ìµë¥  ì²´í¬
annual_check = avg_annual > 5.0  # ì—° 5% ì´ìƒ
safety_checks[f'ì—°ìˆ˜ìµë¥  ({avg_annual:+.1f}% > 5%)'] = annual_check

# 6. ìŠ¬ë¦¬í”¼ì§€ ë¯¼ê°ë„
spread_after_slip = avg_spread  # ì´ë¯¸ ìŠ¬ë¦¬í”¼ì§€ ë°˜ì˜ë¨
slip_check = spread_after_slip > 0
safety_checks[f'ìŠ¬ë¦¬í”¼ì§€ í›„ Spread ({spread_after_slip:+.1f}% > 0)'] = slip_check

# ê²°ê³¼ ì¶œë ¥
print('\n  [ì²´í¬ë¦¬ìŠ¤íŠ¸]')
print('  ' + '-' * 50)
passed = 0
for check_name, result in safety_checks.items():
    status = 'âœ… PASS' if result else 'âŒ FAIL'
    print(f'    {status}  {check_name}')
    if result:
        passed += 1

print('  ' + '-' * 50)
print(f'    í†µê³¼: {passed}/{len(safety_checks)}')

# ìµœì¢… íŒì •
print('\n  [ì „ëµ ìœ íš¨ì„± íŒì •]')
if passed == len(safety_checks):
    print('    ğŸ”¥ ë§¤ìš° ì•ˆì „ - ì‹¤ì „ íˆ¬ì… ê°€ëŠ¥')
elif passed >= len(safety_checks) * 0.7:
    print('    âœ… ì–‘í˜¸ - ì†Œì•¡ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ì¶”ì²œ')
elif passed >= len(safety_checks) * 0.5:
    print('    âš ï¸  ì£¼ì˜ - ì¶”ê°€ ê²€ì¦ í•„ìš”')
else:
    print('    âŒ ìœ„í—˜ - ì „ëµ ì¬ê²€í†  í•„ìš”')

# ì €ì¥
results_df.to_csv('backtest_v2_results.csv', index=False)
print(f'\nê²°ê³¼ ì €ì¥: backtest_v2_results.csv')

print('\n' + '=' * 70)
print('V2 ë°±í…ŒìŠ¤íŠ¸ ì™„ë£Œ!')
print('=' * 70)
