#!/usr/bin/env python3
"""
V2 ëª¨ë¸ ì „ì²´ ë°±í…ŒìŠ¤íŠ¸ (1ê°œì›”, 3ê°œì›”, 6ê°œì›”)

Usage:
    python3 run_full_backtest_v2.py
"""

import warnings
warnings.filterwarnings('ignore')

import logging
logging.basicConfig(level=logging.WARNING)

import pandas as pd
import numpy as np
from scipy import stats
from datetime import datetime
from ml.features import FeatureEngineer
from ml.model import MLRanker

# ì„¤ì •
HORIZONS = [21, 63, 126]  # 1ê°œì›”, 3ê°œì›”, 6ê°œì›”
HORIZON_NAMES = {21: '1ê°œì›”', 63: '3ê°œì›”', 126: '6ê°œì›”'}
TRAIN_YEARS = 3

print('=' * 70)
print('ğŸš€ V2 ëª¨ë¸ ì¢…í•© ë°±í…ŒìŠ¤íŠ¸ (1/3/6ê°œì›”)')
print(f'   {datetime.now().strftime("%Y-%m-%d %H:%M")}')
print('=' * 70)

# ============================================================================
# ë°ì´í„° ë¡œë“œ
# ============================================================================
print('\n[1/4] ë°ì´í„° ë¡œë“œ ì¤‘...')

fe = FeatureEngineer('krx_stock_data.db')
df_base = fe.prepare_ml_data(
    start_date='20150101',
    end_date='20260128',
    target_horizon=21,  # ì¼ë‹¨ 21ì¼ë¡œ ë¡œë“œ
    min_market_cap=500_000_000_000,
    include_fundamental=True
)

# í”¼ì²˜ ë¶„ë¥˜
momentum_features = [c for c in fe.MOMENTUM_FEATURES if c in df_base.columns]
volume_features = [c for c in fe.VOLUME_FEATURES if c in df_base.columns]
volatility_features = [c for c in fe.VOLATILITY_FEATURES if c in df_base.columns]
intuition_features = [c for c in fe.INTUITION_FEATURES if c in df_base.columns]
traditional_features = [c for c in fe.TRADITIONAL_FEATURES if c in df_base.columns]
fund_features = [c for c in fe.FUNDAMENTAL_FEATURES if c in df_base.columns]

all_features = (momentum_features + volume_features + volatility_features +
                intuition_features + traditional_features + fund_features)

print(f'   ì´ ë°ì´í„°: {len(df_base):,} rows')
print(f'   í”¼ì²˜: {len(all_features)}ê°œ')

# ============================================================================
# Forward Return ê³„ì‚°
# ============================================================================
print('\n[2/4] Forward Return ê³„ì‚° ì¤‘...')

df_base = df_base.sort_values(['stock_code', 'date'])
grouped = df_base.groupby('stock_code')

for horizon in HORIZONS:
    col_name = f'forward_return_{horizon}d'
    if col_name not in df_base.columns:
        df_base[col_name] = grouped['closing_price'].transform(
            lambda x: x.pct_change(horizon).shift(-horizon)
        )
        df_base[col_name] = df_base[col_name].clip(-0.5, 0.5)

    target_col = f'target_rank_{horizon}d'
    df_base[target_col] = df_base.groupby('date')[col_name].rank(pct=True)

print(f'   Forward returns ê³„ì‚° ì™„ë£Œ: {HORIZONS}')

df_base['year'] = df_base['date'].str[:4].astype(int)
years = sorted(df_base['year'].unique())

# ============================================================================
# Walk-Forward ë°±í…ŒìŠ¤íŠ¸
# ============================================================================
print('\n[3/4] Walk-Forward ë°±í…ŒìŠ¤íŠ¸...')
print('-' * 70)

all_results = []

for horizon in HORIZONS:
    horizon_name = HORIZON_NAMES[horizon]
    target_col = f'target_rank_{horizon}d'
    return_col = f'forward_return_{horizon}d'

    # Buffer ê³„ì‚° (horizon ê±°ë˜ì¼ + ì—¬ìœ )
    buffer_month = 12 - (horizon // 21 + 1)
    buffer_month = max(1, min(buffer_month, 9))

    print(f'\n  [{horizon_name} ({horizon}ì¼)]')

    for test_year in years:
        train_start = test_year - TRAIN_YEARS
        train_end = test_year - 1

        train_cutoff = f'{train_end}{buffer_month:02d}01'

        train_df = df_base[(df_base['year'] >= train_start) &
                           (df_base['year'] <= train_end) &
                           (df_base['date'] <= train_cutoff)].copy()
        test_df = df_base[df_base['year'] == test_year].copy()

        if len(train_df) < 1000 or len(test_df) < 100:
            continue

        # ëª¨ë¸ í•™ìŠµ
        model = MLRanker(
            feature_cols=all_features,
            target_col=target_col,
            model_type='regressor',
            time_decay=0.7
        )
        model.train(train_df)

        # ì˜ˆì¸¡
        test_df['pred_score'] = model.predict(test_df)
        test_df['pred_rank'] = test_df.groupby('date')['pred_score'].rank(pct=True)

        # Quintile ìˆ˜ìµë¥ 
        test_df['quintile'] = pd.qcut(
            test_df['pred_rank'], 5,
            labels=[1,2,3,4,5], duplicates='drop'
        )

        quintile_ret = test_df.groupby('quintile')[return_col].mean() * 100

        q1 = quintile_ret.get(1, np.nan)
        q5 = quintile_ret.get(5, np.nan)
        spread = q5 - q1 if not (np.isnan(q5) or np.isnan(q1)) else np.nan

        # IC ê³„ì‚°
        ic, _ = stats.spearmanr(
            test_df['pred_score'].fillna(0),
            test_df[return_col].fillna(0)
        )

        all_results.append({
            'horizon': horizon_name,
            'horizon_days': horizon,
            'year': test_year,
            'Q1': q1,
            'Q5': q5,
            'spread': spread,
            'IC': ic
        })

        if not np.isnan(spread):
            bar = 'â–ˆ' * int(max(0, min(spread + 5, 15)))
            print(f'    {test_year}: Q1={q1:+5.1f}% Q5={q5:+5.1f}% Spread={spread:+5.1f}% IC={ic:+.3f} {bar}')

# ============================================================================
# ê²°ê³¼ ë¶„ì„
# ============================================================================
results_df = pd.DataFrame(all_results)

print('\n' + '=' * 70)
print('ğŸ“Š V2 ì¢…í•© ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼')
print('=' * 70)

# Pivot table
print('\n[ì—°ë„ë³„ Spread ìš”ì•½]')
print('-' * 70)

pivot = results_df.pivot_table(
    index='year',
    columns='horizon',
    values='spread',
    aggfunc='first'
)
pivot = pivot[[HORIZON_NAMES[h] for h in HORIZONS]]
print(pivot.round(1).to_string())

# IC Pivot
print('\n[ì—°ë„ë³„ IC ìš”ì•½]')
print('-' * 70)

ic_pivot = results_df.pivot_table(
    index='year',
    columns='horizon',
    values='IC',
    aggfunc='first'
)
ic_pivot = ic_pivot[[HORIZON_NAMES[h] for h in HORIZONS]]
print(ic_pivot.round(3).to_string())

# ë³´ìœ  ê¸°ê°„ë³„ ì„±ê³¼ ìš”ì•½
print('\n' + '-' * 70)
print('[ë³´ìœ  ê¸°ê°„ë³„ ì„±ê³¼ ìš”ì•½]')
print('-' * 70)
print(f'{"ë³´ìœ ê¸°ê°„":<10} {"í‰ê·  Q5":>10} {"í‰ê·  Q1":>10} {"í‰ê·  Spread":>12} {"ì—°í™˜ì‚°":>10} {"í‰ê·  IC":>10} {"ICì–‘ìˆ˜ìœ¨":>8}')
print('-' * 70)

summary_data = []
for horizon in HORIZONS:
    horizon_name = HORIZON_NAMES[horizon]
    h_results = results_df[results_df['horizon_days'] == horizon].dropna(subset=['spread'])

    if len(h_results) == 0:
        continue

    avg_q5 = h_results['Q5'].mean()
    avg_q1 = h_results['Q1'].mean()
    avg_spread = h_results['spread'].mean()
    avg_ic = h_results['IC'].mean()
    ic_positive = (h_results['IC'] > 0).sum() / len(h_results) * 100

    # ì—°í™˜ì‚°
    periods_per_year = 252 / horizon
    annual_spread = avg_spread * periods_per_year

    print(f'{horizon_name:<10} {avg_q5:>+9.1f}% {avg_q1:>+9.1f}% {avg_spread:>+11.1f}% {annual_spread:>+9.1f}% {avg_ic:>+9.3f} {ic_positive:>7.0f}%')

    summary_data.append({
        'ë³´ìœ ê¸°ê°„': horizon_name,
        'horizon_days': horizon,
        'í‰ê·  Q5': avg_q5,
        'í‰ê·  Q1': avg_q1,
        'í‰ê·  Spread': avg_spread,
        'ì—°í™˜ì‚° Spread': annual_spread,
        'í‰ê·  IC': avg_ic,
        'IC ì–‘ìˆ˜ìœ¨': ic_positive
    })

print('-' * 70)

# ìµœì¢… íŒì •
print('\n[ìµœì¢… íŒì •]')
print('-' * 70)

best_horizon = max(summary_data, key=lambda x: x['í‰ê·  IC'])
print(f'âœ… ìµœì  ë³´ìœ ê¸°ê°„: {best_horizon["ë³´ìœ ê¸°ê°„"]} (IC {best_horizon["í‰ê·  IC"]:+.3f}, Spread {best_horizon["í‰ê·  Spread"]:+.1f}%)')

avg_ic_all = sum(d['í‰ê·  IC'] for d in summary_data) / len(summary_data)
avg_ic_positive = sum(d['IC ì–‘ìˆ˜ìœ¨'] for d in summary_data) / len(summary_data)

if avg_ic_all >= 0.05 and avg_ic_positive >= 70:
    print('ğŸ”¥ ëª¨ë¸ ì„±ëŠ¥: ìš°ìˆ˜ (í‰ê·  IC 0.05+, IC ì–‘ìˆ˜ìœ¨ 70%+)')
elif avg_ic_all >= 0.02 and avg_ic_positive >= 50:
    print('âœ… ëª¨ë¸ ì„±ëŠ¥: ì–‘í˜¸ (í‰ê·  IC 0.02+)')
else:
    print('âš ï¸ ëª¨ë¸ ì„±ëŠ¥: ê°œì„  í•„ìš”')

avg_annual = sum(d['ì—°í™˜ì‚° Spread'] for d in summary_data) / len(summary_data)
if avg_annual >= 20:
    print(f'ğŸ”¥ ìˆ˜ìµì„±: ìš°ìˆ˜ (í‰ê·  ì—°í™˜ì‚° Spread {avg_annual:+.1f}%)')
elif avg_annual >= 10:
    print(f'âœ… ìˆ˜ìµì„±: ì–‘í˜¸ (í‰ê·  ì—°í™˜ì‚° Spread {avg_annual:+.1f}%)')
else:
    print(f'âš ï¸ ìˆ˜ìµì„±: ë³´í†µ (í‰ê·  ì—°í™˜ì‚° Spread {avg_annual:+.1f}%)')

# ì €ì¥
results_df.to_csv('backtest_v2_full_results.csv', index=False)
summary_df = pd.DataFrame(summary_data)
summary_df.to_csv('backtest_v2_summary.csv', index=False)

print('\n[íŒŒì¼ ì €ì¥]')
print('  - ìƒì„¸ ê²°ê³¼: backtest_v2_full_results.csv')
print('  - ìš”ì•½: backtest_v2_summary.csv')

print('\n' + '=' * 70)
print('V2 ì¢…í•© ë°±í…ŒìŠ¤íŠ¸ ì™„ë£Œ!')
print('=' * 70)
