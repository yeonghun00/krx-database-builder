"""
Feature Engineering V2 - Î™®Îç∏ Ïã¨ÌèêÏÜåÏÉùÏà†

Î≥ÄÍ≤ΩÏÇ¨Ìï≠:
1. Î™®Î©òÌÖÄ/ÏàòÍ∏â ÌîºÏ≤ò ÎåÄÌè≠ Í∞ïÌôî (Ïû¨Î¨¥ 30-40% Î™©Ìëú)
2. ÏÑπÌÑ∞ Ï§ëÎ¶ΩÌôî (Sector Neutralization)
3. Delta ÌîºÏ≤ò Ï∂îÍ∞Ä (QoQ, YoY Î≥ÄÌôî)
4. Î≥∏Îä• Ï†ÑÎûµ ÌîºÏ≤ò (ÎÇôÌè≠Í≥ºÎåÄ, Í±∞ÎûòÎüâ Ìè≠Î∞ú, Í≥ºÍ±∞ ÏòÅÍ¥ë)
"""

import pandas as pd
import numpy as np
import sqlite3
import logging
from typing import List, Optional
from pathlib import Path

# Import financial feature generator
import sys
sys.path.insert(0, str(Path(__file__).parent.parent))
from features.financial_features import FinancialFeatureGenerator


class FeatureEngineer:
    """V3: ÌÄÄÌä∏ ÌåÄÏû• ÌîºÎìúÎ∞± Î∞òÏòÅ - ÌîºÏ≤ò Îã§Ïù¥Ïñ¥Ìä∏ + Î≥∏Îä• Í∞ïÌôî"""

    # =========================================================================
    # ÌîºÏ≤ò Í∑∏Î£π Ï†ïÏùò (V3: 45Í∞ú ‚Üí 25Í∞úÎ°ú ÏïïÏ∂ï)
    # =========================================================================

    # [Í∑∏Î£π 1] Î™®Î©òÌÖÄ ÌîºÏ≤ò - 15Í∞ú ‚Üí 4Í∞úÎ°ú ÏïïÏ∂ï!
    # "Îã®Í∏∞(5d), Ï§ëÍ∏∞(60d), Ïû•Í∏∞(126d), ÏãúÏû•ÎåÄÎπÑ(RS)" Îßå ÎÇ®ÍπÄ
    MOMENTUM_FEATURES = [
        'mom_5d',                # Îã®Í∏∞ Î™®Î©òÌÖÄ (1Ï£º)
        'mom_60d',               # Ï§ëÍ∏∞ Î™®Î©òÌÖÄ (3Í∞úÏõî)
        'mom_126d',              # Ïû•Í∏∞ Î™®Î©òÌÖÄ (6Í∞úÏõî)
        'rs_vs_market_20d',      # ÏãúÏû• ÎåÄÎπÑ ÏÉÅÎåÄÍ∞ïÎèÑ (ÌïµÏã¨!)
    ]

    # [Í∑∏Î£π 2] ÏàòÍ∏â/Í±∞ÎûòÎüâ ÌîºÏ≤ò - Í∞ïÌôî! (ÏÑ∏Î†• Í∞êÏßÄ = ÌïµÏã¨)
    VOLUME_FEATURES = [
        'volume_surprise',       # Í±∞ÎûòÎüâ Ìè≠Î∞ú (20Ïùº ÌèâÍ∑† ÎåÄÎπÑ) üî•
        'volume_trend',          # Í±∞ÎûòÎüâ Ï∂îÏÑ∏ (5Ïùº vs 20Ïùº)
        'value_surprise',        # Í±∞ÎûòÎåÄÍ∏à Ìè≠Î∞ú
        'accumulation_index',    # ÎàÑÏ†Å/Î∞∞Î∂Ñ ÏßÄÌëú
        'smart_money_flow',      # Ïä§ÎßàÌä∏Î®∏Îãà ÌùêÎ¶Ñ
        'volume_breakout',       # Í±∞ÎûòÎüâ ÎèåÌåå Ïã†Ìò∏ (Ïã†Í∑ú)
    ]

    # [Í∑∏Î£π 3] Î≥ÄÎèôÏÑ±/Î¶¨Ïä§ÌÅ¨ ÌîºÏ≤ò - Ïú†ÏßÄ
    VOLATILITY_FEATURES = [
        'volatility_20d',
        'volatility_ratio',      # Îã®Í∏∞/Ïû•Í∏∞ Î≥ÄÎèôÏÑ± ÎπÑÏú® (VCP)
        'drawdown_from_high',    # Í≥†Ï†ê ÎåÄÎπÑ ÎÇôÌè≠ üî•
        'recovery_from_low',     # Ï†ÄÏ†ê ÎåÄÎπÑ Î∞òÎì±
    ]

    # [Í∑∏Î£π 4] Î≥∏Îä• Ï†ÑÎûµ ÌîºÏ≤ò - Í≤∞Ìï© ÌîºÏ≤ò Ï∂îÍ∞Ä! üî•
    INTUITION_FEATURES = [
        'past_glory_1y',         # 1ÎÖÑÍ∞Ñ ÏµúÎåÄ ÏÉÅÏäπÎ•†
        'fallen_angel_score',    # Ï∂îÎùΩÌïú Ï≤úÏÇ¨ Ï†êÏàò
        'vcp_score',             # Volatility Contraction Pattern
        # === Ïã†Í∑ú: Í≤∞Ìï© ÌîºÏ≤ò (Interaction Features) ===
        'glory_correction_volume',  # ÏòÅÍ¥ë * ÎÇôÌè≠ * Í±∞ÎûòÎüâÌè≠Î∞ú üî•üî•üî•
        'fear_greed_signal',        # Í≥µÌè¨ ÏÜç ÌÉêÏöï Ïã†Ìò∏
        'smart_accumulation',       # Ïä§ÎßàÌä∏Î®∏Îãà Îß§Ïßë Ïã†Ìò∏
    ]

    # [Í∑∏Î£π 5] Ï†ÑÌÜµÏ†Å Í∏∞Ïà† ÏßÄÌëú - Ï∂ïÏÜå
    TRADITIONAL_FEATURES = [
        'rsi_14',
        'bb_squeeze',            # Î≥ºÎ¶∞Ï†ÄÎ∞¥Îìú ÏàòÏ∂ï
    ]

    # [Í∑∏Î£π 6] Ïû¨Î¨¥ ÌîºÏ≤ò - Rank Ï†úÍ±∞, Delta/Z-scoreÎßå!
    FUNDAMENTAL_FEATURES = [
        # Delta ÌîºÏ≤òÎßå (Î≥ÄÌôîÍ∞Ä Ï§ëÏöî!)
        'roe_delta_qoq',         # ROE Î∂ÑÍ∏∞ Î≥ÄÌôî
        'roe_sector_zscore',     # ROE ÏÑπÌÑ∞ ÎåÄÎπÑ Z-score (Ïã†Í∑ú)
        'revenue_growth_accel',  # Îß§Ï∂ú ÏÑ±Ïû• Í∞ÄÏÜçÎèÑ
        'margin_improvement',    # ÎßàÏßÑ Í∞úÏÑ†
    ]

    # Ï†ÑÏ≤¥ ÌîºÏ≤ò Î¶¨Ïä§Ìä∏
    FEATURE_COLUMNS = (
        MOMENTUM_FEATURES +
        VOLUME_FEATURES +
        VOLATILITY_FEATURES +
        INTUITION_FEATURES +
        TRADITIONAL_FEATURES +
        FUNDAMENTAL_FEATURES
    )

    def __init__(self, db_path: str = "krx_stock_data.db"):
        self.db_path = db_path
        self.logger = logging.getLogger(__name__)

    def load_raw_data(self, start_date: str, end_date: str,
                      markets: List[str] = None) -> pd.DataFrame:
        """Load raw OHLCV data from database."""
        markets = markets or ['kospi', 'kosdaq']
        market_placeholders = ','.join(['?' for _ in markets])

        query = f"""
        SELECT
            dp.stock_code,
            dp.date,
            dp.market_type,
            dp.opening_price,
            dp.high_price,
            dp.low_price,
            dp.closing_price,
            dp.volume,
            dp.value,
            dp.market_cap,
            s.current_name as name,
            s.current_sector_type as sector
        FROM daily_prices dp
        JOIN stocks s ON dp.stock_code = s.stock_code
        WHERE dp.date >= ? AND dp.date <= ?
          AND dp.market_type IN ({market_placeholders})
          AND dp.closing_price > 0
          AND dp.volume > 0
        ORDER BY dp.stock_code, dp.date
        """

        params = [start_date, end_date] + markets

        conn = sqlite3.connect(self.db_path)
        df = pd.read_sql_query(query, conn, params=params)
        conn.close()

        self.logger.info(f"Loaded {len(df):,} rows from {start_date} to {end_date}")
        return df

    def compute_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """Compute all V2 features."""
        self.logger.info("Computing V2 features (momentum-heavy)...")

        df = df.sort_values(['stock_code', 'date']).copy()
        grouped = df.groupby('stock_code')

        # Í∏∞Î≥∏ Í≥ÑÏÇ∞
        df['return'] = grouped['closing_price'].pct_change()
        df['log_return'] = np.log1p(df['return'])

        # ================================================================
        # [Í∑∏Î£π 1] Î™®Î©òÌÖÄ ÌîºÏ≤ò
        # ================================================================
        self._compute_momentum_features(df, grouped)

        # ================================================================
        # [Í∑∏Î£π 2] ÏàòÍ∏â/Í±∞ÎûòÎüâ ÌîºÏ≤ò
        # ================================================================
        self._compute_volume_features(df, grouped)

        # ================================================================
        # [Í∑∏Î£π 3] Î≥ÄÎèôÏÑ±/Î¶¨Ïä§ÌÅ¨ ÌîºÏ≤ò
        # ================================================================
        self._compute_volatility_features(df, grouped)

        # ================================================================
        # [Í∑∏Î£π 4] Î≥∏Îä• Ï†ÑÎûµ ÌîºÏ≤ò
        # ================================================================
        self._compute_intuition_features(df, grouped)

        # ================================================================
        # [Í∑∏Î£π 5] Ï†ÑÌÜµÏ†Å Í∏∞Ïà† ÏßÄÌëú
        # ================================================================
        self._compute_traditional_features(df, grouped)

        # ================================================================
        # ÏÑπÌÑ∞ Ï§ëÎ¶ΩÌôî (Sector Neutralization)
        # ================================================================
        self._apply_sector_neutralization(df)

        # Cleanup
        self._cleanup_intermediate_cols(df)

        self.logger.info(f"Computed {len(self.FEATURE_COLUMNS)} V2 features")
        return df

    def _compute_momentum_features(self, df: pd.DataFrame, grouped) -> None:
        """Î™®Î©òÌÖÄ ÌîºÏ≤ò Í≥ÑÏÇ∞ (V3: ÏïïÏ∂ïÎê® - 5d, 60d, 126d, RSÎßå)"""

        # Multi-timeframe momentum (V3: 5, 60, 126ÏùºÎßå ÏÇ¨Ïö©)
        for period in [5, 20, 60, 120, 126]:
            df[f'mom_{period}d'] = grouped['closing_price'].transform(
                lambda x: x.pct_change(period)
            )

        # Moving averages
        for period in [5, 20, 60, 120]:
            df[f'ma_{period}'] = grouped['closing_price'].transform(
                lambda x: x.rolling(period, min_periods=period//2).mean()
            )
            df[f'dist_ma_{period}'] = (
                df['closing_price'] / df[f'ma_{period}'].clip(lower=1) - 1
            )

        # MA Trend (Ï†ïÎ∞∞Ïó¥ Ïó¨Î∂Ä): 5 > 20 > 60
        df['ma_trend'] = (
            (df['ma_5'] > df['ma_20']).astype(float) * 0.5 +
            (df['ma_20'] > df['ma_60']).astype(float) * 0.5
        )

        # Relative Strength vs Market
        for period in [20, 60]:
            stock_ret = df[f'mom_{period}d']
            market_ret = df.groupby('date')[f'mom_{period}d'].transform('median')
            df[f'rs_vs_market_{period}d'] = stock_ret - market_ret

        # Momentum Consistency (ÏÉÅÏäπÏùº ÎπÑÏú®)
        df['up_day'] = (df['return'] > 0).astype(float)
        df['mom_consistency'] = grouped['up_day'].transform(
            lambda x: x.rolling(20, min_periods=10).mean()
        )

        # Momentum Acceleration (ÏµúÍ∑º Î™®Î©òÌÖÄ / Í≥ºÍ±∞ Î™®Î©òÌÖÄ)
        df['mom_acceleration'] = df['mom_20d'] / df['mom_60d'].clip(lower=0.01).abs()
        df['mom_acceleration'] = df['mom_acceleration'].clip(-5, 5)

    def _compute_volume_features(self, df: pd.DataFrame, grouped) -> None:
        """ÏàòÍ∏â/Í±∞ÎûòÎüâ ÌîºÏ≤ò Í≥ÑÏÇ∞"""

        # Volume averages
        df['vol_5d'] = grouped['volume'].transform(
            lambda x: x.rolling(5, min_periods=3).mean()
        )
        df['vol_20d'] = grouped['volume'].transform(
            lambda x: x.rolling(20, min_periods=10).mean()
        )

        # Volume Surprise (Í±∞ÎûòÎüâ Ìè≠Î∞ú)
        df['volume_surprise'] = df['volume'] / df['vol_20d'].clip(lower=1)

        # Volume Trend
        df['volume_trend'] = df['vol_5d'] / df['vol_20d'].clip(lower=1)

        # Value Surprise (Í±∞ÎûòÎåÄÍ∏à Ìè≠Î∞ú)
        df['value_20d'] = grouped['value'].transform(
            lambda x: x.rolling(20, min_periods=10).mean()
        )
        df['value_surprise'] = df['value'] / df['value_20d'].clip(lower=1)

        # Smart Money Flow (Ï¢ÖÍ∞Ä ÏúÑÏπò * Í±∞ÎûòÎüâ)
        # Ï¢ÖÍ∞ÄÍ∞Ä Í≥†Í∞Ä Í∑ºÏ≤òÎ©¥ Îß§Ïßë, Ï†ÄÍ∞Ä Í∑ºÏ≤òÎ©¥ Ìà¨Îß§
        df['close_location'] = (
            (df['closing_price'] - df['low_price']) /
            (df['high_price'] - df['low_price']).clip(lower=1)
        )
        df['daily_mf'] = (df['close_location'] * 2 - 1) * df['volume']
        df['smart_money_flow'] = grouped['daily_mf'].transform(
            lambda x: x.rolling(20, min_periods=10).sum()
        ) / grouped['volume'].transform(
            lambda x: x.rolling(20, min_periods=10).sum()
        ).clip(lower=1)

        # Accumulation Index
        df['accumulation_index'] = grouped['smart_money_flow'].transform(
            lambda x: x.rolling(10, min_periods=5).mean()
        )

        # Volume Breakout (V3 Ïã†Í∑ú) - Í±∞ÎûòÎüâÏù¥ ÏµúÍ∑º 60Ïùº ÏµúÍ≥† ÎåÄÎπÑ ÏñºÎßàÎÇò ÎÜíÏùÄÏßÄ
        df['vol_60d_max'] = grouped['volume'].transform(
            lambda x: x.rolling(60, min_periods=30).max()
        )
        df['volume_breakout'] = df['volume'] / df['vol_60d_max'].clip(lower=1)

    def _compute_volatility_features(self, df: pd.DataFrame, grouped) -> None:
        """Î≥ÄÎèôÏÑ±/Î¶¨Ïä§ÌÅ¨ ÌîºÏ≤ò Í≥ÑÏÇ∞"""

        # Historical Volatility
        for period in [20, 60]:
            df[f'volatility_{period}d'] = grouped['return'].transform(
                lambda x: x.rolling(period, min_periods=period//2).std() * np.sqrt(252)
            )

        # Volatility Ratio (VCP Ìå®ÌÑ¥ Í∞êÏßÄ)
        df['volatility_ratio'] = (
            df['volatility_20d'] / df['volatility_60d'].clip(lower=0.01)
        )

        # ATR
        df['tr'] = np.maximum(
            df['high_price'] - df['low_price'],
            np.maximum(
                (df['high_price'] - df.groupby('stock_code')['closing_price'].shift(1)).abs(),
                (df['low_price'] - df.groupby('stock_code')['closing_price'].shift(1)).abs()
            )
        )
        df['atr_20'] = grouped['tr'].transform(
            lambda x: x.rolling(20, min_periods=10).mean()
        )
        df['atr_ratio'] = df['tr'] / df['atr_20'].clip(lower=1)

        # Drawdown from High (Í≥†Ï†ê ÎåÄÎπÑ ÎÇôÌè≠)
        df['high_52w'] = grouped['high_price'].transform(
            lambda x: x.rolling(252, min_periods=126).max()
        )
        df['drawdown_from_high'] = df['closing_price'] / df['high_52w'].clip(lower=1) - 1

        # Recovery from Low (Ï†ÄÏ†ê ÎåÄÎπÑ Î∞òÎì±)
        df['low_52w'] = grouped['low_price'].transform(
            lambda x: x.rolling(252, min_periods=126).min()
        )
        df['recovery_from_low'] = df['closing_price'] / df['low_52w'].clip(lower=1) - 1

    def _compute_intuition_features(self, df: pd.DataFrame, grouped) -> None:
        """Î≥∏Îä• Ï†ÑÎûµ ÌîºÏ≤ò: Ï°¥ÎÇò ÏÑº ÎÜà + Ï°∞Ï†ï -30~50%"""

        # Í≥ºÍ±∞Ïùò ÏòÅÍ¥ë (1ÎÖÑÍ∞Ñ ÏµúÎåÄ ÏÉÅÏäπÎ•†)
        df['past_glory_1y'] = df['high_52w'] / df['low_52w'].clip(lower=1) - 1

        # ÏòÅÍ¥ë ÎåÄÎπÑ ÌòÑÏû¨ ÎÇôÌè≠
        df['max_drawdown_from_glory'] = df['drawdown_from_high']

        # Fallen Angel Score (Ï∂îÎùΩÌïú Ï≤úÏÇ¨)
        # Í≥ºÍ±∞Ïóê Ïûò ÎÇòÍ∞îÎäîÎç∞ (glory > 100%) ÏßÄÍ∏à ÎßéÏù¥ Îπ†ÏßÑ (-30% ~ -50%)
        glory_condition = (df['past_glory_1y'] > 1.0).astype(float)
        drawdown_condition = (
            (df['drawdown_from_high'] < -0.30) &
            (df['drawdown_from_high'] > -0.50)
        ).astype(float)
        df['fallen_angel_score'] = glory_condition * drawdown_condition * (
            df['past_glory_1y'] * (-df['drawdown_from_high'])
        )

        # Bounce Potential (Î∞òÎì± Ïû†Ïû¨Î†•)
        # ÎÇôÌè≠ + Í±∞ÎûòÎüâ Ï∂ïÏÜå + Î≥ÄÎèôÏÑ± ÏàòÏ∂ï
        volume_dryup = (df['volume_trend'] < 0.8).astype(float)
        vol_contraction = (df['volatility_ratio'] < 0.7).astype(float)
        df['bounce_potential'] = (
            df['fallen_angel_score'] *
            (1 + volume_dryup * 0.3) *
            (1 + vol_contraction * 0.3)
        )

        # VCP Score (Volatility Contraction Pattern)
        # Î≥ÄÎèôÏÑ± ÏàòÏ∂ï + Í±∞ÎûòÎüâ Ï∂ïÏÜå + Í∞ÄÍ≤© Ìö°Î≥¥
        price_stable = ((df['dist_ma_20'].abs() < 0.05)).astype(float)
        df['vcp_score'] = (
            vol_contraction *
            volume_dryup *
            price_stable *
            df['past_glory_1y'].clip(0, 2)
        )

        # ================================================================
        # V3 Ïã†Í∑ú: Í≤∞Ìï© ÌîºÏ≤ò (Interaction Features) üî•
        # "ÌîºÏ≤òÎ•º ÎÇòÏó¥Îßå ÌïòÏßÄ ÎßêÍ≥†, Î≥∏Îä• Ï†ÑÎûµÏö© Í≤∞Ìï© ÌîºÏ≤òÎ•º ÏßÅÏ†ë ÎßåÎì§Ïñ¥Îùº"
        # ================================================================

        # Glory_Correction_Volume: ÏòÅÍ¥ë * ÎÇôÌè≠ * Í±∞ÎûòÎüâÌè≠Î∞ú
        # "Í≥ºÍ±∞Ïóê ÌôîÎ†§ÌñàÍ≥† + ÏßÄÍ∏à Ï∂©Î∂ÑÌûà Îπ†Ï°åÎäîÎç∞ + Í±∞ÎûòÎüâÏù¥ ÌÑ∞ÏßÄÍ∏∞ ÏãúÏûëÌïú ÎÜà"
        df['glory_correction_volume'] = (
            df['past_glory_1y'].clip(0, 5) *
            (-df['drawdown_from_high']).clip(0, 1) *
            (df['volume_surprise'] - 1).clip(0, 10)
        )

        # Fear_Greed_Signal: Í≥µÌè¨ ÏÜç ÌÉêÏöï Ïã†Ìò∏
        # "ÎÇ®Îì§Ïù¥ Í≥µÌè¨(Volatility)Î•º ÎäêÎÇÑ Îïå ÌÉêÏöï(Volume)ÏùÑ Î∞úÍ≤¨"
        high_volatility = (df['volatility_20d'] > df['volatility_60d']).astype(float)
        volume_spike = (df['volume_surprise'] > 2.0).astype(float)
        price_down = (df['drawdown_from_high'] < -0.20).astype(float)
        df['fear_greed_signal'] = high_volatility * volume_spike * price_down * df['past_glory_1y'].clip(0, 3)

        # Smart_Accumulation: Ïä§ÎßàÌä∏Î®∏Îãà Îß§Ïßë Ïã†Ìò∏
        # "Ï°∞Ïö©Ìûà Îß§Ïßë Ï§ë - Í±∞ÎûòÎüâ Ï¶ùÍ∞Ä + Ïä§ÎßàÌä∏Î®∏Îãà Ïú†ÏûÖ + ÎÇôÌè≠Í≥ºÎåÄ"
        smart_inflow = (df['smart_money_flow'] > 0.3).astype(float)
        df['smart_accumulation'] = (
            smart_inflow *
            (df['accumulation_index'] + 1).clip(0, 2) *
            (-df['drawdown_from_high']).clip(0, 0.5) *
            df['volume_trend'].clip(0.5, 2)
        )

    def _compute_traditional_features(self, df: pd.DataFrame, grouped) -> None:
        """Ï†ÑÌÜµÏ†Å Í∏∞Ïà† ÏßÄÌëú"""

        # RSI
        delta = grouped['closing_price'].diff()
        gain = delta.where(delta > 0, 0)
        loss = (-delta.where(delta < 0, 0))

        avg_gain = grouped['closing_price'].transform(
            lambda x: x.diff().where(x.diff() > 0, 0).rolling(14).mean()
        )
        avg_loss = grouped['closing_price'].transform(
            lambda x: (-x.diff().where(x.diff() < 0, 0)).rolling(14).mean()
        )

        rs = avg_gain / avg_loss.clip(lower=0.001)
        df['rsi_14'] = 100 - (100 / (1 + rs))

        # RSI Divergence (Í∞ÄÍ≤©ÏùÄ Ïã†Ï†ÄÍ∞ÄÏù∏Îç∞ RSIÎäî ÏïÑÎãå Í≤ΩÏö∞ = Î∞òÎì± Ïã†Ìò∏)
        price_new_low = (df['closing_price'] <= df['low_52w'] * 1.05).astype(float)
        rsi_not_low = (df['rsi_14'] > 30).astype(float)
        df['rsi_divergence'] = price_new_low * rsi_not_low

        # Bollinger Bands
        df['bb_mid'] = df['ma_20']
        df['bb_std'] = grouped['closing_price'].transform(
            lambda x: x.rolling(20, min_periods=10).std()
        )
        df['bb_upper'] = df['bb_mid'] + 2 * df['bb_std']
        df['bb_lower'] = df['bb_mid'] - 2 * df['bb_std']
        df['bb_position'] = (
            (df['closing_price'] - df['bb_lower']) /
            (df['bb_upper'] - df['bb_lower']).clip(lower=1)
        )

        # BB Squeeze (Î≥ºÎ¶∞Ï†ÄÎ∞¥Îìú ÏàòÏ∂ï)
        df['bb_width'] = (df['bb_upper'] - df['bb_lower']) / df['bb_mid'].clip(lower=1)
        df['bb_width_avg'] = grouped['bb_width'].transform(
            lambda x: x.rolling(60, min_periods=30).mean()
        )
        df['bb_squeeze'] = (df['bb_width'] < df['bb_width_avg'] * 0.8).astype(float)

    def _apply_sector_neutralization(self, df: pd.DataFrame) -> None:
        """ÏÑπÌÑ∞ Ï§ëÎ¶ΩÌôî: Î™®Îì† ÌîºÏ≤òÎ•º ÏÑπÌÑ∞ ÎÇ¥ ÏàúÏúÑÎ°ú Î≥ÄÌôò"""

        # Sector-relative momentum (ÌïµÏã¨!)
        def sector_zscore(x):
            std = x.std()
            if std < 0.01:
                std = 0.01
            return (x - x.mean()) / std

        df['rs_vs_sector_20d'] = df.groupby(['date', 'sector'])['mom_20d'].transform(sector_zscore)

        # Î™®Î©òÌÖÄ ÌîºÏ≤òÎì§ÏùÑ ÏÑπÌÑ∞ ÎÇ¥ Îû≠ÌÅ¨Î°ú Î≥ÄÌôò
        momentum_cols = ['mom_5d', 'mom_10d', 'mom_20d', 'mom_60d']
        for col in momentum_cols:
            if col in df.columns:
                df[f'{col}_sector_rank'] = df.groupby(['date', 'sector'])[col].rank(pct=True)

    def _cleanup_intermediate_cols(self, df: pd.DataFrame) -> None:
        """Ï§ëÍ∞Ñ Í≥ÑÏÇ∞ Ïª¨Îüº Ï†úÍ±∞"""
        intermediate = [
            'return', 'log_return', 'up_day',
            'ma_5', 'ma_20', 'ma_60', 'ma_120',
            'vol_5d', 'vol_20d', 'value_20d',
            'close_location', 'daily_mf',
            'tr', 'atr_20',
            'high_52w', 'low_52w',
            'bb_mid', 'bb_std', 'bb_upper', 'bb_lower', 'bb_width', 'bb_width_avg',
        ]
        df.drop(columns=intermediate, errors='ignore', inplace=True)

    def load_financial_features(self, start_date: str, end_date: str,
                                min_market_cap: int = 500000000000) -> pd.DataFrame:
        """Load financial features with Delta calculations."""
        self.logger.info("Loading financial features (with deltas)...")

        with FinancialFeatureGenerator(self.db_path) as fin_gen:
            fin_df = fin_gen.generate_features(
                start_date=start_date,
                end_date=end_date,
                min_market_cap=min_market_cap,
                include_ranks=True,
                include_missing_indicators=True
            )

        # Add Delta features (QoQ changes)
        fin_df = fin_df.sort_values(['stock_code', 'date'])
        grouped = fin_df.groupby('stock_code')

        # ROE Delta (Î∂ÑÍ∏∞ Î≥ÄÌôî)
        if 'roe' in fin_df.columns:
            fin_df['roe_prev'] = grouped['roe'].shift(63)  # ~1Î∂ÑÍ∏∞ Ï†Ñ
            fin_df['roe_delta_qoq'] = fin_df['roe'] - fin_df['roe_prev']

            # V3 Ïã†Í∑ú: ROE ÏÑπÌÑ∞ ÎåÄÎπÑ Z-score
            # "Ï†àÎåÄÍ∞í RankÍ∞Ä ÏïÑÎãàÎùº, ÏÑπÌÑ∞ ÎÇ¥ÏóêÏÑú ÏñºÎßàÎÇò ÌäÄÏñ¥ÎÇòÏôîÎäîÏßÄ"
            def sector_zscore(x):
                mean = x.mean()
                std = x.std()
                if std == 0 or pd.isna(std):
                    return 0
                return (x - mean) / std

            if 'sector' in fin_df.columns:
                fin_df['roe_sector_zscore'] = fin_df.groupby(['date', 'sector'])['roe'].transform(sector_zscore)
                fin_df['roe_sector_zscore'] = fin_df['roe_sector_zscore'].clip(-3, 3)
            else:
                fin_df['roe_sector_zscore'] = fin_df.groupby('date')['roe'].transform(sector_zscore)
                fin_df['roe_sector_zscore'] = fin_df['roe_sector_zscore'].clip(-3, 3)

        # Revenue Growth Acceleration
        if 'revenue_yoy' in fin_df.columns:
            fin_df['revenue_yoy_prev'] = grouped['revenue_yoy'].shift(63)
            fin_df['revenue_growth_accel'] = fin_df['revenue_yoy'] - fin_df['revenue_yoy_prev']

        # Margin Improvement
        if 'operating_margin' in fin_df.columns:
            fin_df['margin_prev'] = grouped['operating_margin'].shift(63)
            fin_df['margin_improvement'] = fin_df['operating_margin'] - fin_df['margin_prev']

        # Convert date
        fin_df['date'] = fin_df['date'].dt.strftime('%Y%m%d')

        self.logger.info(f"Loaded {len(fin_df):,} financial records with deltas")
        return fin_df

    def merge_financial_features(self, tech_df: pd.DataFrame,
                                 fin_df: pd.DataFrame) -> pd.DataFrame:
        """Merge technical and financial features."""
        fin_cols = ['stock_code', 'date'] + [
            col for col in self.FUNDAMENTAL_FEATURES
            if col in fin_df.columns
        ]
        fin_subset = fin_df[fin_cols].drop_duplicates(subset=['stock_code', 'date'])

        merged = pd.merge(
            tech_df,
            fin_subset,
            on=['stock_code', 'date'],
            how='left'
        )

        # Fill missing fundamental features
        for col in self.FUNDAMENTAL_FEATURES:
            if col in merged.columns:
                if col.startswith('is_null_'):
                    merged[col] = merged[col].fillna(1)
                elif col.endswith('_rank'):
                    merged[col] = merged[col].fillna(0.5)
                else:
                    merged[col] = merged.groupby('date')[col].transform(
                        lambda x: x.fillna(x.median())
                    )

        return merged

    def add_forward_returns(self, df: pd.DataFrame,
                            horizons: List[int] = None) -> pd.DataFrame:
        """
        Add forward returns using Open-to-Open pricing (Ï†ïÏÑù)

        Signal: TÏùº Ï¢ÖÍ∞Ä Îç∞Ïù¥ÌÑ∞ÍπåÏßÄ Î≥¥Í≥† ÏÉùÏÑ±
        Buy: T+1Ïùº ÏãúÍ∞Ä (Open)
        Sell: T+1+hÏùº ÏãúÍ∞Ä (Open)

        Example (h=21):
          - TÏùº Ï†ÄÎÖÅÏóê Ïã†Ìò∏ ÏÉùÏÑ±
          - T+1Ïùº ÏãúÍ∞ÄÏóê Îß§Ïàò
          - T+22Ïùº ÏãúÍ∞ÄÏóê Îß§ÎèÑ (21 Í±∞ÎûòÏùº Î≥¥Ïú†)
        """
        horizons = horizons or [21]  # V2 Í∏∞Î≥∏Í∞í: 21Ïùº

        df = df.sort_values(['stock_code', 'date']).copy()
        grouped = df.groupby('stock_code')

        for h in horizons:
            col_name = f'forward_return_{h}d'

            # Open-to-Open: T+1 ÏãúÍ∞Ä ‚Üí T+1+h ÏãúÍ∞Ä
            # (T+1+hÏùº ÏãúÍ∞Ä - T+1Ïùº ÏãúÍ∞Ä) / T+1Ïùº ÏãúÍ∞Ä
            open_t1 = grouped['opening_price'].shift(-1)        # T+1 ÏãúÍ∞Ä
            open_t1_h = grouped['opening_price'].shift(-1 - h)  # T+1+h ÏãúÍ∞Ä
            df[col_name] = (open_t1_h - open_t1) / open_t1

            df[col_name] = df[col_name].clip(-0.50, 0.50)

            # V3 Ïã†Í∑ú: Alpha (ÏãúÏû• ÎåÄÎπÑ Ï¥àÍ≥ºÏàòÏùµÎ•†) üî•
            # "ÏΩîÏä§ÌîºÍ∞Ä 5% Ïò§Î•º Îïå ÎÇ¥ Ï¢ÖÎ™©Ïù¥ 5% Ïò§Î•∏ Í±¥ Ïã§Î†•Ïù¥ ÏïÑÎãàÎã§"
            # "ÏãúÏû•Ïù¥ -2% Îπ†Ïßà Îïå +3% Ïò§Î•∏ ÎÜàÏùÑ Ï∞æÏïÑÎùº"
            market_return = df.groupby('date')[col_name].transform('median')
            alpha_col = f'forward_alpha_{h}d'
            df[alpha_col] = df[col_name] - market_return

            # Sector-neutralized target (ÌïµÏã¨!)
            rank_col = f'target_rank_{h}d'
            df[rank_col] = df.groupby('date')[col_name].rank(pct=True)

            # Alpha rank (V3: Ïù¥Í±∏ ÌÉÄÍ≤üÏúºÎ°ú!)
            alpha_rank_col = f'target_alpha_rank_{h}d'
            df[alpha_rank_col] = df.groupby('date')[alpha_col].rank(pct=True)

            # Sector-relative rank
            sector_rank_col = f'target_sector_rank_{h}d'
            df[sector_rank_col] = df.groupby(['date', 'sector'])[col_name].rank(pct=True)

        return df

    def filter_universe(self, df: pd.DataFrame,
                        min_price: int = 1000,
                        min_market_cap: int = 500000000000,
                        min_value: int = 10000000000) -> pd.DataFrame:
        """Filter stock universe."""
        original_len = len(df)

        df = df[df['closing_price'] >= min_price]
        df = df[df['market_cap'] >= min_market_cap]
        df = df[df['value'] >= min_value]

        # Drop rows with NaN in key features
        key_features = ['mom_20d', 'volume_surprise', 'volatility_20d']
        key_features = [f for f in key_features if f in df.columns]
        df = df.dropna(subset=key_features)

        self.logger.info(f"Filtered: {original_len:,} -> {len(df):,} rows")
        return df

    def prepare_ml_data(self, start_date: str, end_date: str,
                        target_horizon: int = 21,  # V2: Í∏∞Î≥∏ 21Ïùº
                        min_market_cap: int = 500000000000,
                        include_fundamental: bool = True) -> pd.DataFrame:
        """Full pipeline for ML data preparation."""

        # 1ÎÖÑ Î≤ÑÌçº
        buffer_start = str(int(start_date[:4]) - 1) + start_date[4:]

        # Step 1: Load and compute technical features
        df = self.load_raw_data(buffer_start, end_date)
        df = self.compute_features(df)

        # Step 2: Load and merge financial features
        if include_fundamental:
            fin_df = self.load_financial_features(start_date, end_date, min_market_cap)
            df = self.merge_financial_features(df, fin_df)

        # Step 3: Add forward returns
        df = self.add_forward_returns(df, [target_horizon])

        # Step 4: Filter universe
        df = self.filter_universe(df, min_market_cap=min_market_cap)

        # Filter to requested date range
        df = df[df['date'] >= start_date]

        # Feature count
        tech_count = len([c for c in df.columns if c in
                         self.MOMENTUM_FEATURES + self.VOLUME_FEATURES +
                         self.VOLATILITY_FEATURES + self.INTUITION_FEATURES +
                         self.TRADITIONAL_FEATURES])
        fund_count = len([c for c in self.FUNDAMENTAL_FEATURES if c in df.columns])

        self.logger.info(f"V2 ML data: {len(df):,} samples")
        self.logger.info(f"  Technical: {tech_count}, Fundamental: {fund_count}")
        self.logger.info(f"  Target ratio: {fund_count/(tech_count+fund_count)*100:.0f}% fundamental (Î™©Ìëú: 30-40%)")

        return df


# =============================================================================
# CLI Entry Point
# =============================================================================

if __name__ == '__main__':
    logging.basicConfig(level=logging.INFO)

    fe = FeatureEngineer('krx_stock_data.db')
    df = fe.prepare_ml_data(
        start_date='20240101',
        end_date='20260128',
        target_horizon=21,
        include_fundamental=True
    )

    print(f"\nÏ¥ù ÌîºÏ≤ò Ïàò: {len([c for c in df.columns if c in fe.FEATURE_COLUMNS])}")
    print(f"Îç∞Ïù¥ÌÑ∞ ÌÅ¨Í∏∞: {len(df):,} rows")
